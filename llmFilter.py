from llama_cpp import Llama
import json
import pandas as pd
from database import database

# Charger le mod√®le local
llm = Llama(
    model_path="models/Phi-3-mini-4k-instruct-q4.gguf",
    n_ctx=2048,
    verbose=False
)

from llama_cpp import Llama
from textwrap import dedent

llm = Llama(
    model_path="models/Phi-3-mini-4k-instruct-q4.gguf",
    n_ctx=2048,
    verbose=False
)

# Mots-cl√©s discriminants par grand th√®me ‚Äì √† adapter librement
KEYWORDS = {
    "Formation de base":          ["AFP", "CFC", "Bachelor", "Master", "doctorat", "universit√©", "HES", "ES"],
    "Formation compl√©mentaire":   ["compl√©mentaire", "brevet", "CAS", "DAS", "MAS", "formations continues"],
    "Dur√©e":                      ["0", "1", "2", "3", "4", "5", "6", "7", "8", "ans", "ann√©e"],
    "Nature":                     ["exp√©rience", "pr√©alable", "m√™me type"],
    "Autonomie de d√©cision":      ["consignes", "directives", "autonome", "approuve"],
    "Responsabilit√©s budg√©taires":["budget", "financier", "facturation", "paiements", "suivi"],
    # "Responsabilit√©s de planification √† court terme":
    #                                 ["court terme", "plan", "optimisation", "proc√©dure"],
    # "Responsabilit√©s de planification √† long terme":
    #                                 ["long terme", "prospective", "anticiper", "recherches", "√©tudes"],
    # "Impact externe des prestations":
    #                                 ["image", "repr√©sentatif", "cons√©quences", "tiers"],
    # "Impact interne des prestations":
    #                                 ["co√ªts", "bon fonctionnement", "irr√©versibles"],
    # "Connaissances linguistiques":["fran√ßais", "langue", "bilingue", "trilingue"],
    # "Nature des communications internes":["communications", "√©changes", "n√©gociations", "d√©cisions"],
    # "Nature des communications externes":["communications", "informer", "explication", "n√©gociations"],
    # "Complexit√© de l'environnement":["difficult√©s", "adaptabilit√©", "flexibilit√©"],
    # "Evolution de l'environnement":["√©volution", "processus", "rapide"],
    # "Diversit√© des missions":     ["missions", "t√¢ches", "diverses"],
    # "Diversit√© et quantit√© des postes √† g√©rer":
    #                                 ["poste", "g√®re", "grand nombre", "activit√©s"],
    # "R√¥le dans la gestion des ressources humaines":
    #                                 ["animation", "conduite", "recrutement", "formation"],
    # "Innovation":                 ["adapter", "cr√©er", "innovatrice", "concepts"]
}

def choose_best_pair(title: str, pairs: list[dict]) -> int:
    """
    Utilise un prompt riche en contraintes + mots-cl√©s pour forcer la s√©lection correcte.
    Retourne l‚Äôindice (0-based) du meilleur couple question-r√©ponse.
    """
    # üîë R√©cup√®re les mots-cl√©s pertinents, sinon liste vide
    kw = ", ".join(KEYWORDS.get(title, []))

    prompt = dedent(f"""
    Tu es √©valuateur¬∑trice RH, sp√©cialiste du r√©f√©rentiel ANMEA.

    T√ÇCHE :
      ‚Ä¢ Pour chaque couple question / phrase candidate, choisis la **SEULE** phrase qui r√©pond
        parfaitement et explicitement √† la question.
      ‚Ä¢  prends en meilleure choix le couple ayant comme phrases contenant les mots-cl√©s importants suivants: {kw if kw else ''}. 
      ‚Ä¢ Ne retiens pas les phrases g√©n√©riques, incompl√®tes ou hors-sujet.
      ‚Ä¢ Ignore les phrases tr√®s courtes du type ‚ÄòFormation professionnelle requise‚Äô,
        ‚ÄòComp√©tences requises‚Äô, etc.
      ‚Ä¢ Accorde davantage de poids :
          
          ‚Äì aux phrases contenant des verbes d‚Äôaction pertinents.
      ‚Ä¢ Ta r√©ponse doit √™tre **un nombre entier unique** correspondant au bon choix.

    LISTE DES COUPLES :
    """).strip() + "\n\n"

    for i, pr in enumerate(pairs, 1):
        prompt += f"{i}. QUESTION : {pr['question']}\n   PHRASE   : {pr['sentence']}\n\n"

    prompt += "R√©ponds uniquement avec le chiffre du meilleur choix."

    # Appel mod√®le
    out = llm.create_chat_completion(
        messages=[{"role": "user", "content": prompt}],
        max_tokens=5,
        temperature=0.1
    )
    reply = out["choices"][0]["message"]["content"].strip()
    print(f"‚Üí LLM a re√ßu le prompt :\n{prompt}")  # logging

    print(f"‚Üí LLM a r√©pondu : '{reply}'")  # logging

    try:
        return int(reply) - 1            # conversion 1-based ‚Üí 0-based
    except Exception:
        return 0                         # fallback s√ªr




data=database("data.db")
data.connect()
df_matches=data.read_json("all_matches.json")

# Filtrer les lignes dont la phrase contient "Formation et exp√©riences professionnelles requises"
df_matches = df_matches[~df_matches["sentence"].str.contains("Formation et exp√©riences professionnelles requises", case=False, na=False)]

df_matches = df_matches[~df_matches["sentence"].str.contains("Activit√©s et responsabilit√©s principales", case=False, na=False)]

df_matches = df_matches[~df_matches["sentence"].str.contains("Responsable hi√©rarchique direct", case=False, na=False)]


# Liste des titres uniques
titles = df_matches["title"].unique()

# R√©sultats finaux
results = []

for title in titles:
    group = df_matches[df_matches["title"] == title]
    MAX_PAIRS = 10
    group = group.sort_values("score", ascending=False).head(MAX_PAIRS)
    pairs = group[["question", "sentence", "score", "pts"]].to_dict("records")

    best_idx = choose_best_pair(title,pairs)
    if 0 <= best_idx < len(pairs):
        best = pairs[best_idx]
        results.append({
            "title": title,
            "question": best["question"],
            "sentence": best["sentence"],
            "score": best["score"],
            "pts": best["pts"]
        })

# Sauvegarde dans after_llm.json
with open("results/after_llm.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

    json_content_str = json.dumps(results, ensure_ascii=False)
    data.execute_query('''DELETE FROM ResultatsJSON WHERE filename = ?''', ("after_llm.json",))
    data.execute_query('''
    INSERT INTO ResultatsJSON (filename, json_content) VALUES (?, ?)
''', ("after_llm.json", json_content_str))
    data.commit()
data.close()
